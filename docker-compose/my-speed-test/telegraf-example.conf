[global_tags]

# [agent]
#   interval = "60s"
#   round_interval = true
#   metric_batch_size = 1000
#   metric_buffer_limit = 10000
#   collection_jitter = "0s"
#   flush_interval = "10s"
#   flush_jitter = "0s"
#   precision = ""
#   hostname = ""
#   omit_hostname = false

# Influx settings
[[outputs.influxdb_v2]]
  urls =["$INFLUX_HOST"]
  ## API token for authentication.
  token = "$INFLUX_TOKEN"
  ## Organization is the name of the organization you wish to write to; must exist.
  organization = "homelab"
  ## Destination bucket to write into.
  bucket = "$INFLUX_DB"

[[inputs.cpu]]
  percpu = true
  totalcpu = true
  collect_cpu_time = false
  report_active = false

[[inputs.disk]]
  ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]

#[[inputs.temp]]

[[inputs.diskio]]

[[inputs.kernel]]

[[inputs.mem]]

[[inputs.processes]]

[[inputs.swap]]

[[inputs.sensors]]

[[inputs.system]]

[[inputs.netstat]]

# Query given DNS server and gives statistics
[[inputs.dns_query]]
  ## servers to query
  servers = ["$DNS1_IP"]

[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
  container_names = []
  timeout = "5s"
  perdevice = false
  perdevice_include = ["cpu", "blkio", "network"]
  total = true
  total_include = ["cpu", "blkio", "network"]

# Read logging output from the Docker engine
#[[inputs.docker_log]]
  ## Docker Endpoint
  ##   To use TCP, set endpoint = "tcp://[ip]:[port]"
  ##   To use environment variables (ie, docker-machine), set endpoint = "ENV"
  #endpoint = "unix:///var/run/docker.sock"
  ## Set the source tag for the metrics to the container ID hostname, eg first 12 chars
  #source_tag = false

# Read metrics from one or many postgresql servers
[[inputs.postgresql]]
  ## specify address via a url matching:
  ##   postgres://[pqgotest[:password]]@localhost[/dbname]?sslmode=[disable|verify-ca|verify-full]
  ## or a simple string:
  ##   host=localhost user=pqgotest password=... sslmode=... dbname=app_production
  ##
  ## All connection parameters are optional.
  ##
  ## Without the dbname parameter, the driver will default to a database
  ## with the same name as the user. This dbname is just for instantiating a
  ## connection with the server and doesn't restrict the databases we are trying
  ## to grab metrics for.
  ##
  address = $POSTGRES_CONFIG

#[[inputs.directory_monitor]]
#  ## The directory to monitor and read files from.
#  directory = ""
#  ## The directory to move finished files to.
#  finished_directory = ""

#[[inputs.smart]]
#  attributes = true

# Read metrics from SMART storage devices using smartclt's JSON output
#[[inputs.smartctl]]
    ## Optionally specify the path to the smartctl executable
    # path = "/usr/sbin/smartctl"

    ## Devices to include or exclude
    ## By default, the plugin will use all devices found in the output of
    ## `smartctl --scan`. Only one option is allowed at a time. If set, include
    ## sets the specific devices to scan, while exclude omits specific devices.
    # devices_include = []
    # devices_exclude = []
    ## Use sudo
    ## On most platforms used, smartctl requires root access. Setting 'use_sudo'
    ## to true will make use of sudo to run smartctl. Sudo must be configured to
    ## allow the telegraf user to run smartctl without a password.
    #use_sudo = true
    ## Skip checking disks in specified power mode
    ## Defaults to "standby" to not wake up disks that have stopped rotating.
    ## For full details on the options here, see the --nocheck section in the
    ## smartctl man page. Choose from:
    ##   * never: always check the device
    ##   * sleep: check the device unless it is in sleep mode
    ##   * standby: check the device unless it is in sleep or standby mode
    ##   * idle: check the device unless it is in sleep, standby, or idle mode
    # nocheck = "standby"

    ## Timeout for the cli command to complete
    # timeout = "86400s"
